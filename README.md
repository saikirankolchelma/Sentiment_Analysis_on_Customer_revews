ğŸš€ Customer Sentiment Analysis Application ğŸš€
This project implements a Customer Sentiment Analysis application as per the task:
"Train an LLM on product reviews (from Amazon or Kaggle datasets) to classify positive, negative, and neutral sentiments."

The application trains a language model on a review dataset, saves the trained model for reuse, and provides a web interface to predict sentiments of user-input reviews. Itâ€™s built with a modular architecture using FastAPI (backend) ğŸŒ, Streamlit (frontend) ğŸ–¥ï¸, and SQLite (database) ğŸ’¾, ensuring scalability and ease of use.

ğŸ—ï¸ Architecture Overview ğŸ—ï¸

Components ğŸ§©
Data Processing (data_processing.py):

Loads and preprocesses the review dataset (train.ft.txt.bz2). ğŸ“‚

Stores predictions in an SQLite database. ğŸ’¾

Model (model.py):

Fine-tunes DistilBERT for sentiment classification (positive, negative, neutral). ğŸ¤–

Saves/loads the trained model for efficiency. ğŸ’ª

Backend (api.py):

FastAPI server exposing /predict/ and /reviews/ endpoints. ğŸŒ

Handles sentiment predictions and database interactions. ğŸ”§

Frontend (frontend.py):

Streamlit interface for user input and result display. ğŸ–¥ï¸âœ¨

Utilities (utils.py):

Logging setup for debugging and monitoring. ğŸ“Š

Main Script (main.py):

Orchestrates training (if needed) and server startup. âš™ï¸

Workflow ğŸ”„

Startup:

main.py checks for a trained model. If absent, it trains DistilBERT on the dataset and saves it. ğŸ§ 

Launches FastAPI , then Streamlit . ğŸš€

Prediction:

User enters a review in Streamlit . âœï¸

Streamlit sends a POST request to FastAPIâ€™s /predict/. ğŸ“¤

FastAPI uses the trained model to predict sentiment, stores it in SQLite, and returns the result. ğŸ”®

Review History:

FastAPIâ€™s /reviews/ endpoint fetches stored reviews from SQLite for display. ğŸ“œ

Diagram ğŸ“Š

[User] â†’ [Streamlit Frontend] â†’ [FastAPI Backend] â†’ [DistilBERT Model]
                            â†“                  â†‘
                       [SQLite DB] â†-----------

                       
ğŸ“‹ Requirements ğŸ“‹

    Dependencies ğŸ“¦
    Python: 3.9 ğŸ
    Packages:
    fastapi
    uvicorn
    streamlit
    langchain
    langchain_community
    transformers
    torch
    requests
    scikit-learn
    accelerate>=0.26.0
    sqlite3 (built into Python)
 Save this as requirements.txt.

Conda Environment Creation ğŸŒ±

Create Environment:

    conda create -n sentiment_env python=3.9

Activate Environment:

    conda activate sentiment_env

Install Dependencies:

    pip install -r requirements.txt

ğŸ¤– Language Model Used ğŸ¤–

LLM: DistilBERT ğŸ§ 

Why DistilBERT?

Efficiency: ğŸš€ DistilBERT (distilbert-base-uncased) is a distilled version of BERT, with 40% fewer parameters and 60% faster inference, making it ideal for a resource-constrained demo while retaining strong NLP performance.

Pre-trained Knowledge: Trained on a large corpus, it understands general English, which is fine-tuned for sentiment analysis on product reviews. ğŸ“š

Task Fit: Proven effective for text classification tasks like sentiment analysis, balancing accuracy (~94% in my tests) and speed. âš¡

Alternatives Considered:

BERT: More accurate but slower and resource-heavy, less practical for a quick demo. ğŸ¢

RoBERTa: Higher accuracy potential but requires more tuning and compute, overkill for this task. ğŸšœ

Fine-Tuning:

Trained on 1000 samples from a 3.6M-row Amazon/Kaggle dataset (train.ft.txt.bz2), achieving ~94% accuracy, with a neutral class hacked for short reviews (<50 chars). âœ¨

ğŸ“‚ Folder Structure ğŸ“‚

    sentiment_app/
    â”œâ”€â”€ data_processing.py      # Data preprocessing logic
    â”œâ”€â”€ model.py                # Model training and saving logic
    â”œâ”€â”€ api.py                  # FastAPI backend logic
    â”œâ”€â”€ frontend.py             # Streamlit frontend logic
    â”œâ”€â”€ utils.py                # Utility functions (logging, etc.)
    â”œâ”€â”€ main.py                 # Main script to orchestrate training and server startup
    â”œâ”€â”€ requirements.txt         # List of dependencies
    â”œâ”€â”€ logs/                   # Created at runtime for logging
    â”œâ”€â”€ database.db             # SQLite database created at runtime
    â”œâ”€â”€ trained_model/          # Directory for saving the trained model
    â””â”€â”€ results/                # Training outputs (metrics, etc.)

ğŸš€ How to Run ğŸš€

1. Setup Environment ğŸŒ±

conda create -n sentiment_env python=3.9

conda activate sentiment_env

pip install -r requirements.txt

3. Place Dataset ğŸ“‚

   
Ensure train.ft.txt.bz2 is in     folder 

5. Run Application ğŸƒâ€â™‚ï¸

cd sentiment_app

python main.py

First run trains the model (~15 min), saves it to trained_model/. ğŸ§ 

Subsequent runs load the saved model instantly. âš¡

6. Access ğŸ“²

Open http://localhost:8501 in a browser.

Enter a review and click "Analyze." âœï¸

ğŸ“ Notes ğŸ“

Dataset: Uses train.ft.txt.bz2 (assumed Amazon/Kaggle reviews in fastText format). ğŸ“‚

Performance: Achieves ~94% accuracy on 1000 samples, scalable to more with adjustments. ğŸ“ˆ

Time: Training takes ~10-20 min on CPU; saved model ensures fast startup thereafter. â³

ğŸ’¡ Why This Approach? ğŸ’¡

Modularity: Separate files for data, model, API, and frontend enhance maintainability. ğŸ§©

Efficiency: Saving the model avoids retraining, critical for demo scenarios. âš¡

User Experience: Streamlit provides a simple, interactive interface. ğŸ–¥ï¸âœ¨

Scalability: FastAPI and SQLite support future expansion (e.g., more endpoints, larger datasets). ğŸŒŸ
